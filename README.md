# Real-time News Article Classification App

## Introduction
This project is a Streamlit-based web application designed to analyze news articles in real-time. The app allows users to search for articles on a specified topic, classify them by category, perform sentiment analysis, recognize named entities, and generate both extractive and abstractive summaries of article content.


https://github.com/user-attachments/assets/2c3edb76-62d6-4e43-9d41-fe45edb9bdad


## Project Structure
The project is organized as follows:

- **app/** - Contains the main backend files for data fetching, classification, sentiment analysis, NER, and summarization.
  - `data_collection.py` - Handles real-time data fetching and preprocessing.
  - `category_classification.py` - Implements the classification model using a pre-trained RoBERTa model.
  - `sentiment_analysis.py` - Performs sentiment analysis on news content.
  - `ner_extraction.py` - Extracts named entities from the articles.
  - `summarization.py` - Generates both extractive and abstractive summaries.
- **models/** - Contains pre-trained models or saved classifiers.
  - `roberta_model/` - Directory for storing a pre-trained RoBERTa model for category classification.
- `app.py` - Main Streamlit application file, managing the user interface and integrating backend functionalities.
- `requirements.txt` - Lists all required Python packages.
- `README.md` - Project documentation in markdown format.

## Installation
To set up the environment, follow these steps:

```bash
# Clone the repository
git clone https://github.com/username/news-classification.git
cd news-classification

# Install the required packages
pip install -r requirements.txt
```

# Usage
Run the Streamlit app with the following command:
```bash
streamlit run app.py
```
Once running, the app will prompt you to enter a topic of interest. It will then fetch relevant articles, display their content, and provide various analytical insights such as classification, sentiment analysis, named entity recognition, and summarization.

## Features
The application provides the following functionalities:

- **Real-time Data Collection**: Fetches and preprocesses news articles based on a user-provided topic using `data_collection.py`.
- **Category Classification**: Classifies the selected article into a predefined category using the pre-trained RoBERTa model, implemented in `category_classification.py`.
- **Sentiment Analysis**: Determines the sentiment of the article, whether positive, negative, or neutral, using `sentiment_analysis.py`.
- **Named Entity Recognition (NER)**: Identifies and extracts entities like characters, protagonists, character traits, and relationships using `ner_extraction.py`.
- **Summarization**: Provides both extractive and abstractive summaries of the article content, generated by `summarization.py`.

## News Article Classification
The classification of news articles is implemented in `category_classification.py` using Hugging Face's RoBERTa model. Here are the key steps involved:

- **Data Loading and Preprocessing**: The script loads training and test data from CSV files located in the `models/` directory. Class labels are adjusted to start from zero, and a sample of 1000 training examples is selected for training.
- **Model Initialization**: A RoBERTa model is fine-tuned on the training dataset, loaded with a sequence classification head for four categories: **World**, **Sports**, **Business**, and **Sci/Tech**.
- **Training**: The model is trained using a custom `NewsDataset` class and a PyTorch DataLoader, with an AdamW optimizer. The training loop performs backpropagation and updates the model's weights based on the classification loss.
- **Classification**: After training, the model and tokenizer are saved to the `models/roberta_model/` directory. The `classify_news` function loads the saved model and predicts the category of a given news article.

## News Data Collection
The `data_collection.py` script uses the News API to fetch recent news articles on a specified topic. This module contains two primary functions:

- **fetch_article_content**: Retrieves the full content of a news article by parsing its URL. The function uses BeautifulSoup to extract paragraphs from the article's HTML, returning the concatenated text content.
- **fetch_news**: Queries the News API based on a user-specified topic, fetching a list of relevant articles in English. Each article includes metadata such as the title, description, source, and URL. The results are returned as a pandas DataFrame for easy manipulation.

## Character and Relationship Extraction
The `ner_extraction.py` module uses Natural Language Processing (NLP) to identify characters, their traits, and relationships in a news article or story. Key functionalities include:

- **Character Identification and Protagonist Detection**: Uses spaCy to list all characters mentioned in the text and determine the protagonist based on frequency and syntactic role.
- **Coreference Resolution**: Applies Stanza's coreference resolution to unify references to the same character within the text, providing coherent character analysis.
- **Trait Extraction**: Analyzes sentences to associate each character with descriptive traits by identifying noun-adjective pairs.
- **Relationship Analysis**: Evaluates character relationships based on shared and unique traits, assigning labels like "strong," "neutral," or "distant" based on similarity.

## Sentiment Analysis
The `sentiment_analysis.py` module uses a pre-trained RoBERTa model for analyzing the sentiment of news articles or texts. The sentiment analysis is performed as follows:

- **Model Initialization**: Utilizes the `cardiffnlp/twitter-roberta-base-sentiment` model through Hugging Face's `transformers` library for reliable sentiment classification.
- **Sentiment Classification**: Labels text as **Positive**, **Neutral**, or **Negative**, with a confidence score.

## Summarization
The `summarization.py` module provides both extractive and abstractive summarization methods to condense news articles or other texts.

- **Extractive Summarization**: Ranks sentences based on word frequency using spaCy and selects the most important sentences for a summary.
- **Abstractive Summarization**: Uses a BART model (`facebook/bart-large-cnn`) to generate a concise, rewritten version of the text.
- **Summary Options**: The module allows choosing between **extractive**, **abstractive**, or **both** methods, with customizable summary length.

## Models
This project utilizes a pre-trained RoBERTa model for news category classification, stored in the `models/roberta_model/` directory. The model is fine-tuned to classify news articles into categories such as **World**, **Sports**, **Business**, and **Sci/Tech**.

**Model Download:** The pre-trained model weights are available for download due to their size. You can access them here: [Link to Google Drive folder](https://drive.google.com/drive/folders/1-1VXJY-6IWGJaKJBOsanx53Es_OX3w-a?usp=sharing).

- Zip is already prepared.
- Contents of zip should be placed in models/roberta_model
  
## Future Enhancements
Potential future enhancements could include:

- **Adding more categories for classification**: Expanding the range of categories to improve the granularity of article classification.
- **Extending NER to include other types of entities**: Enhancing the named entity recognition capabilities to identify additional entities such as locations, organizations, and events.
- **Improving summarization methods for higher accuracy**: Developing more sophisticated summarization techniques to generate more precise and contextually relevant summaries.
